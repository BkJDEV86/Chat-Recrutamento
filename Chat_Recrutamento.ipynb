{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v2vdShXfOS8"
   },
   "source": [
    "# Chat de Recrutamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10532,
     "status": "ok",
     "timestamp": 1742312872085,
     "user": {
      "displayName": "Fernando Amaral",
      "userId": "13956145547499510680"
     },
     "user_tz": 180
    },
    "id": "YL7qYZt8fNAq"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sentence_transformers import SentenceTransformer, util # Util é da similaridade do cosseno.\n",
    "# Os transformadores de frases são criados em arquiteturas de transformadores, que se destacam na captura de relacionamentos contextuais em dados sequenciais.\n",
    "# Os transformadores utilizam mecanismos de autoatenção, permitindo que o modelo pondere diferentes partes do texto de entrada ao criar embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_-ksHvAfPZO"
   },
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1742312970785,
     "user": {
      "displayName": "Fernando Amaral",
      "userId": "13956145547499510680"
     },
     "user_tz": 180
    },
    "id": "zjHPaLhbh8DM",
    "outputId": "d1517a80-0ab1-4762-fe55-0932c8a1a473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeiras 5 linhas da tabela faq':\n",
      "\n",
      "(1, 'Como posso me candidatar a uma vaga?', 'Você pode se candidatar acessando nosso site oficial e preenchendo o formulário na área de Carreiras.')\n",
      "(2, 'Quanto tempo leva para eu receber uma resposta após me candidatar?', 'Normalmente, entramos em contato dentro de 7 a 10 dias úteis, mas isso pode variar conforme o volume de vagas.')\n",
      "(3, 'Quais são as etapas do processo seletivo?', 'O processo seletivo inclui triagem de currículos, entrevista inicial, entrevista técnica e entrevista final.')\n",
      "(4, 'Quais benefícios a empresa oferece?', 'Oferecemos assistência médica, vale-alimentação, bonificação, horários flexíveis e home office para algumas funções.')\n",
      "(5, 'Posso remarcar a data da minha entrevista?', 'Sim, basta entrar em contato com o RH com pelo menos 24 horas de antecedência.')\n"
     ]
    }
   ],
   "source": [
    "# Visualiza o banco de dados\n",
    "conn = sqlite3.connect(\"recrutamento.db\")\n",
    "cursor = conn.cursor()\n",
    "# Um cursor de banco de dados é uma estrutura de controle que permite a um aplicativo navegar e processar linhas de dados em um conjunto de resultados,\n",
    "# uma de cada vez.\n",
    "\n",
    "cursor.execute(\"SELECT * FROM faq LIMIT 5;\")\n",
    "# fetchall() é um método usado para buscar todas as linhas restantes de um resultado de consulta de um banco de dados\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\nPrimeiras 5 linhas da tabela faq':\\n\")\n",
    "for linha in resultados:\n",
    "    print(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742313037508,
     "user": {
      "displayName": "Fernando Amaral",
      "userId": "13956145547499510680"
     },
     "user_tz": 180
    },
    "id": "YaGTqc4zfPgL"
   },
   "outputs": [],
   "source": [
    "# A função do banco de dados.\n",
    "def carregar_faq_do_banco():\n",
    "    conn = sqlite3.connect(\"recrutamento.db\")\n",
    "    cursor = conn.cursor()\n",
    "  \n",
    "\n",
    "    cursor.execute(\"SELECT pergunta, resposta FROM faq\")\n",
    "    faq_data = cursor.fetchall()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return faq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RicjbMMfPnZ"
   },
   "source": [
    "### Cria Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742313132074,
     "user": {
      "displayName": "Fernando Amaral",
      "userId": "13956145547499510680"
     },
     "user_tz": 180
    },
    "id": "Y7FfU8PsfPtY"
   },
   "outputs": [],
   "source": [
    "def criar_chatbot():\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2') # Cria o modelo\n",
    "\n",
    "    faq_data = carregar_faq_do_banco() # Carrega o banco\n",
    "\n",
    "    perguntas_faq = [qa[0] for qa in faq_data]\n",
    "    respostas_faq = [qa[1] for qa in faq_data]\n",
    "    # Os embeddings são vetores criados por modelos de aprendizado de máquina com a finalidade de capturar dados significativos sobre cada objeto.\n",
    "    # perguntas_embeddings são as representações vetoriais numéricas\n",
    "    # das perguntas .\n",
    "    perguntas_embeddings = model.encode(perguntas_faq, convert_to_tensor=True) \n",
    "\n",
    "    return model, perguntas_faq, respostas_faq, perguntas_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VId15Qz-fP0Z"
   },
   "source": [
    "### Obtêm Respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1742313249585,
     "user": {
      "displayName": "Fernando Amaral",
      "userId": "13956145547499510680"
     },
     "user_tz": 180
    },
    "id": "aGe_B9RxfP6u"
   },
   "outputs": [],
   "source": [
    "def obter_resposta(model, perguntas_faq, respostas_faq, perguntas_embeddings, pergunta_usuario):\n",
    "\n",
    "    emb_usuario = model.encode(pergunta_usuario, convert_to_tensor=True) # Tranforma a pergunta do usuário em um Embeddings.\n",
    "\n",
    "    similaridades = util.cos_sim(emb_usuario, perguntas_embeddings) # Similaridade entre o embeddings da pergunta e o embeddings do usuário.\n",
    "\n",
    "    idx_melhor = similaridades[0].argmax().item() # Da similaridade pegamos o índice da melhor pergunta. Argmax() retorna o índice do maior valor do array \n",
    "   \n",
    "    # Retorna a resposta com o melhor índice e a similaridade da pegunta de melhor índice.\n",
    "    return respostas_faq[idx_melhor], similaridades[0][idx_melhor].item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaB-J5ywfQDe"
   },
   "source": [
    "### Mantém Conversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742313337685,
     "user": {
      "displayName": "Fernando Amaral",
      "userId": "13956145547499510680"
     },
     "user_tz": 180
    },
    "id": "XZpqYkt7fQIr"
   },
   "outputs": [],
   "source": [
    "def conversar_com_chatbot(model, perguntas_faq, respostas_faq, perguntas_embeddings):\n",
    "    print(\"Olá! Sou o Chatbot de Recrutamento. Como posso ajudar?\\n\")\n",
    "\n",
    "    while True:\n",
    "        pergunta = input(\"Você: \")\n",
    "        if pergunta.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "            print(\"Chatbot: Obrigado por conversar. Até mais!\")\n",
    "            break\n",
    "\n",
    "        resposta, score = obter_resposta(\n",
    "            model,\n",
    "            perguntas_faq,\n",
    "            respostas_faq,\n",
    "            perguntas_embeddings,\n",
    "            pergunta\n",
    "        )\n",
    "\n",
    "        print(f\"Chatbot: {resposta}\\n(Similaridade: {score:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsAWH1OzfbKk"
   },
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93196,
     "status": "ok",
     "timestamp": 1742313459498,
     "user": {
      "displayName": "Fernando Amaral",
      "userId": "13956145547499510680"
     },
     "user_tz": 180
    },
    "id": "7n71n5QzfbRr",
    "outputId": "02f43cc7-a56d-491e-c59c-0611a1a92755"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá! Sou o Chatbot de Recrutamento. Como posso ajudar?\n",
      "\n",
      "Você: Como eu posso me candidatar a uma vaga?\n",
      "Chatbot: Você pode se candidatar acessando nosso site oficial e preenchendo o formulário na área de Carreiras.\n",
      "(Similaridade: 0.97)\n",
      "\n",
      "Você: Posso remarcar minha entrevista?\n",
      "Chatbot: Sim, basta entrar em contato com o RH com pelo menos 24 horas de antecedência.\n",
      "(Similaridade: 0.79)\n",
      "\n",
      "Você: sair\n",
      "Chatbot: Obrigado por conversar. Até mais!\n"
     ]
    }
   ],
   "source": [
    "model, perguntas_faq, respostas_faq, perguntas_embeddings = criar_chatbot()\n",
    "\n",
    "conversar_com_chatbot(model, perguntas_faq, respostas_faq, perguntas_embeddings)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
